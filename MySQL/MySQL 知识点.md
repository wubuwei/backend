注：内容大部分来自极客时间课程[《MySQL 实战45讲》](http://gk.link/a/10jIv)

## 1. MySQL 逻辑架构

![MySQL 逻辑架构图](https://raw.githubusercontent.com/wubuwei/backend_image/master/MySQL%E9%80%BB%E8%BE%91%E6%9E%B6%E6%9E%84%E5%9B%BE.png)

大体来说，`MySQL` 可以分为 `Server 层`和 `存储引擎层` 两部分。

- `Server 层` 包括 `连接器`、`查询缓存`、`分析器`、`优化器`、`执行器` 等，涵盖 `MySQL` 的大多数核心服务功能，以及所有的 `内置函数（如日期、时间、数学和加密函数等）`，所有跨存储引擎的功能都在这一层实现，比如 `存储过程`、`触发器`、`视图` 等。

- `存储引擎层` 负责数据的存储和提取。其架构模式是插件式的，支持 `InnoDB`、`MyISAM`、`Memory` 等多个存储引擎。现在最常用的存储引擎是 `InnoDB`，它从 `MySQL 5.5.5` 版本开始成为了默认存储引擎。


### 连接器

数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。

问题：

有时候 `MySQL` 占用内存涨得特别快，这是因为 `MySQL` 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（`OOM`:`Out Of Memory`），从现象看就是 `MySQL` 异常重启了。

解决方式：

1. 定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。
2. 如果你用的是 `MySQL 5.7` 或更新版本，可以在每次执行一个比较大的操作后，通过执行 `mysql_reset_connection` 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。

### 查询缓存

查询缓存往往弊大于利。

查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。

`MySQL 8.0` 版本直接将查询缓存的整块功能删掉了，也就是说 `8.0` 开始彻底没有这个功能了。


### 分析器

分析器先会做 `词法分析` 识别 `select` 等关键词，再做 `语法分析` 判断是否符合 `MySQL` 语法。

分析器还会进行语义分析，比如查询未知列的错误是出现在这里


### 优化器

优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（`join`）的时候，决定各个表的连接顺序。

### 执行器

`MySQL` 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。

数据库的慢查询日志中看到一个 `rows_examined` 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。

在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 `rows_examined` 并不是完全相同的。


## 2. MySQL 日志系统

与查询流程不一样的是，更新流程还涉及两个重要的日志模块：`redo log（重做日志）` 和 `binlog（归档日志）`


### redo log

`redo log` 是 `InnoDB` 引擎特有的日志。

`WAL` 技术的全称是 `Write-Ahead Logging`，它的关键点就是先写日志，再写磁盘

当有一条记录需要更新的时候，`InnoDB` 引擎就会先把记录写到 `redo log` 里面，并更新内存，这个时候更新就算完成了。同时，`InnoDB` 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。

有了 `redo log`，`InnoDB` 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为 `crash-safe`。

`innodb_flush_log_at_trx_commit` 这个参数设置成 `1` 的时候，表示每次事务的 `redo log` 都直接持久化到磁盘。可以保证 `MySQL` 异常重启之后数据不丢失。

### binlog

`MySQL` 的 `Server` 层日志，称为 `binlog`。

为什么有两份日志系统？因为最开始 `MySQL` 里并没有 `InnoDB` 引擎。`MySQL` 自带的引擎是 `MyISAM`，但是 `MyISAM` 没有 `crash-safe` 的能力，`binlog` 日志只能用于归档。而 `InnoDB` 是另一个公司以插件形式引入 `MySQL` 的，既然只依靠 `binlog` 是没有 `crash-safe` 能力的，所以 `InnoDB` 使用另外一套日志系统——也就是 `redo log` 来实现 `crash-safe` 能力。

`sync_binlog` 这个参数设置成 `1` 的时候，表示每次事务的 `binlog` 都持久化到磁盘。可以保证 MySQL 异常重启之后 `binlog` 不丢失。


### redo log 与 binlog 对比不同

1. `redo log` 是 `InnoDB` 引擎特有的；`binlog` 是 `MySQL` 的 `Server` 层实现的，所有引擎都可以使用。
2. `redo log` 是物理日志，记录的是“在某个数据页上做了什么修改”；`binlog` 是逻辑日志，记录的是这个语句的原始逻辑，比如“`给 ID=2 这一行的 c 字段加 1 `”。
3. `redo log` 是循环写的，空间固定会用完；`binlog` 是可以追加写入的。“追加写”是指 `binlog` 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。


逻辑日志可以给别的数据库，别的引擎使用，已经大家都讲得通这个“逻辑”；
物理日志就只有“我”自己能用，别人没有共享我的“物理格式”

### update 语句时的内部流程
1. 执行器先找引擎取 `ID=2` 这一行。`ID` 是主键，引擎直接用树搜索找到这一行。如果` ID=2` 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。
2. 执行器拿到引擎给的行数据，把这个值加上 `1`，比如原来是 `N`，现在就是 `N+1`，得到新的一行数据，再调用引擎接口写入这行新数据。
3. 引擎将这行新数据更新到内存中，同时将这个更新操作记录到 `redo log` 里面，此时 `redo log` 处于 `prepare` 状态。然后告知执行器执行完成了，随时可以提交事务。
4. 执行器生成这个操作的 `binlog`，并把 `binlog` 写入磁盘。
5. 执行器调用引擎的提交事务接口，引擎把刚刚写入的 `redo log` 改成提交（`commit`）状态，更新完成。

### 一天一备跟一周一备的对比

好处是“最长恢复时间”更短。

在一天一备的模式里，最坏情况下需要应用一天的 `binlog`。比如，你每天 `0` 点做一次全量备份，而要恢复出一个到昨天晚上 `23` 点的备份。

一周一备最坏情况就要应用一周的 `binlog` 了。

恢复目标时间 `RTO(Recovery Time Objective)`
当然这个是有成本的，因为更频繁全量备份需要消耗更多存储空间，所以这个 `RTO` 是成本换来的，就需要你根据业务重要性来评估了。

## 3. 事务隔离

`事务` 就是要保证一组数据库操作，要么全部成功，要么全部失败。在 `MySQL` 中，事务支持是在引擎层实现的。`MySQL `原生的 `MyISAM` 引擎就不支持事务，这也是 `MyISAM` 被 `InnoDB` 取代的重要原因之一。

### 事务特性 ACID
- 原子性（`Atomicity`）
- 一致性（`Consistency`）
- 隔离性（`Isolation`）
- 持久性（`Durability`）

### 隔离级别

当数据库有多个事务同时执行的时候，就可能出现脏读（`dirty read`）、不可重复读（`non-repeatable read`）、幻读（`phantom read`），为了解决这些问题，就有了 `事务隔离` 的概念。

- 脏读：当数据库中一个 `事务A` 正在修改一个数据但是还未提交或者回滚，另一个 `事务B` 来读取了修改后的内容并且使用了，之后 `事务A` 提交了，此时就引起了脏读。此情况仅会发生在：读未提交的的隔离级别。
- 不可重复读：在一个 `事务A` 中多次操作数据，在事务操作过程中(未最终提交)，`事务B` 也才做了处理，并且该值发生了改变，这时候就会导致 `事务A` 在操作的时候，发现数据与第一次不一样了，就是不可重复读。此情况仅会发生在：读未提交、读提交的隔离级别。
- 幻读：一个事务按相同的查询条件重新读取以前检索过的数据，却发现其他事务插入了满足其查询条件的新数据，这种现象就称为幻读。
幻读是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，比如这种修改涉及到表中的“全部数据行”。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入“一行新数据”。那么，以后就会发生操作第一个事务的用户发现表中还存在没有修改的数据行，就好象发生了幻觉一样。
一般解决幻读的方法是增加 `范围锁 RangeS`，锁定检索范围为只读，这样就避免了幻读。
此情况会回发生在：读未提交、读提交、可重复读的隔离级别。

SQL 标准的事务隔离级别包括：
- 读未提交（`read uncommitted`）：一个事务还没提交时，它做的变更就能被其它事务看到。
- 读提交（`read committed`）：一个事务提交之后，它做的变更才会被其它事务看到。
- 可重复读（`repeatable table`）：一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的，未提交变更对其它事务也是不可见的。
- 串行化（`serializable`）：对于同一行记录，`写` 会加 `写锁`，`读` 会加 `读锁`。当出现读写冲突时候，后访问的事务必须等前一个事务执行完成，才能继续执行。

隔离得越严实，效率就会越低。
四种情况并行性能依次降低，安全性依次提高。

`MySQL` 查看事务隔离级别命令： `show variables like 'transaction_isolation';`

### 事务隔离的实现

每条记录在更新的时候都会同时记录一条回滚操作。同一条记录在系统中可以存在多个版本，这就是数据库的多版本并发控制（`MVCC`）。

回滚日志什么时候删除？系统会判断当没有事务需要用到这些回滚日志的时候，回滚日志会被删除。

什么时候不需要了？当系统里没有比这个回滚日志更早的 `read-view` 的时候。

为什么尽量不要使用长事务？长事务意味着系统里面会存在很老的事务视图，在这个事务提交之前，回滚记录都要保留，这会导致大量占用存储空间。除此之外，长事务还占用锁资源，可能会拖垮库。

### 事务的启动方式

1. 显式启动事务语句， `begin` 或 `start transaction`。配套的提交语句是 `commit`，回滚语句是 `rollback`。

2. `set autocommit=0`，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 `select` 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 `commit` 或 `rollback` 语句，或者断开连接。

有些客户端连接框架会默认连接成功后先执行一个 `set autocommit=0` 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。建议总是使用 `set autocommit=1`, 通过显式语句的方式来启动事务。

在 `autocommit` 为 `1` 的情况下，用 `begin` 显式启动的事务，如果执行 `commit` 则提交事务。如果执行 `commit work and chain`，则是提交事务并自动启动下一个事务，这样也省去了再次执行 `begin` 语句的开销。同时带来的好处是从程序开发的角度明确地知道每个语句是否处于事务中。

### 事务的启动时机

`begin/start transaction` 命令并不是一个事务的起点，在执行到它们之后的第一个操作 `InnoDB` 表的语句，事务才真正启动。如果你想要马上启动一个事务，可以使用 `start transaction with consistent snapshot` 这个命令。
- 第一种启动方式，一致性视图是在执行第一个快照读语句时创建的；
- 第二种启动方式，一致性视图是在执行 `start transaction with consistent snapshot` 时创建的。

#### MySQL 中视图的概念
- 一个是 `view`。它是一个用查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是 `create view … `，而它的查询方法与表一样。
- 另一个是 `InnoDB` 在实现 `MVCC` 时用到的一致性读视图，即 `consistent read view`，用于支持 `RC（Read Committed，读提交`）和 `RR（Repeatable Read，可重复读）` 隔离级别的实现。

### 如何避免长事务
```
在 information_schema 库的 innodb_trx 这个表中查询长事务，比如下面这个语句，用于查找持续时间超过 60s 的事务。

select * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))>60
```

在开发过程中，尽可能的减小事务范围，少用长事务，如果无法避免，保证逻辑日志空间足够用，并且支持动态日志空间增长。监控 `Innodb_trx` 表，发现长事务报警。


#### 从应用开发端来看
- 确认是否使用了 `set autocommit=0`。这个确认工作可以在测试环境中开展，把 `MySQL` 的 `general_log` 开起来，然后随便跑一个业务逻辑，通过 `general_log` 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 `1`。
- 确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 `begin/commit` 框起来。我见过有些是业务并没有这个需要，但是也把好几个 `select` 语句放到了事务中。这种只读事务可以去掉。
- 业务连接数据库的时候，根据业务本身的预估，通过 `SET MAX_EXECUTION_TIME` 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。

#### 从数据库端来看
- 监控 `information_schema.Innodb_trx` 表，设置长事务阈值，超过就报警或者 `kill`；
- `Percona` 的 `pt-kill` 这个工具不错，推荐使用；
- 在业务功能测试阶段要求输出所有的 `general_log`，分析日志行为提前发现问题；
- 如果使用的是 `MySQL 5.6` 或者更新版本，把 `innodb_undo_tablespaces` 设置成 `2`（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。

## 4. 索引

索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。

数据库底层存储的核心就是基于数据模型，用于提高读写效率的数据结构，三种常见：哈希表、有序数组和搜索树。
- 哈希表是一种以 `键-值` 存储数据的结构，哈希表这种结构适用于只有等值查询的场景。
- 有序数组在等值查询和范围查询场景中的性能就都非常优秀，但有序数组索引只适用于静态存储引擎。
- 二叉搜索树的特点是：每个节点的左儿子小于父节点，父节点又小于右儿子。二叉树查询的时间复杂度是 `0(logN)`。


在 MySQL 中，索引是在存储引擎层实现的，所以并没有统一的索引标准，即不同存储引擎的索引的工作方式并不一样。


### InnoDB 的索引模型

在 `InnoDB` 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。

`InnoDB` 使用了 `B+` 树索引模型，所以数据都是存储在 `B+` 树中的。

每一个索引在 `InnoDB` 里面对应一棵 `B+` 树。

#### 区分主键和非主键索引
主键列为 ID 的表，表中有字段 k，并且在 k 上有索引
```
mysql> create table T(
id int primary key,
k int not null,
name varchar(16),
index (k))engine=InnoDB;
```
表中 R1~R5 的 (ID,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)
![InnoDB 的索引组织结构](https://raw.githubusercontent.com/wubuwei/backend_image/master/InnoDB%E7%B4%A2%E5%BC%95.png)

从图中看出，根据叶子节点的类型，索引类型分为主键索引和非主键索引。

主键索引的叶子节点存的是整行数据。在 `InnoDB` 里，主键索引也被成为聚簇索引（`clustered index`）。

非主键索引的叶子节点内容是主键的值。在 `InnoDB` 里，非主键索引也被成为二级索引（`secondary index`）。

#### 基于主键索引和普通索引的查询有什么区别
- 如果语句是 `select * from T where ID=500`，即主键查询方式，则只需要搜索 `ID` 这棵 `B+` 树；
- 如果语句是 `select * from T where k=5`，即普通索引查询方式，则需要先搜索 `k` 索引树，得到 `ID` 的值为 `500`，再到 `ID` 索引树搜索一次。这个过程称为回表。

也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。

### 索引维护

一个数据页满了，按照 `B+` 树算法，新增加一个数据页，叫做页分裂，会导致性能下降。空间利用率降低大概`50%`。当相邻的两个数据页利用率很低的时候会做数据页合并，合并的过程是分裂过程的逆过程。

#### 用身份证号做主键还是用自增主键

由于每个非主键索引的叶子节点上都是主键的值。如果用字符串类型的身份证号做主键，那么每个二级索引的叶子节点占用约 `20` 个字节，而如果用整型做主键，则只要 `4` 个字节，如果是长整型（`bigint`）则是 `8` 个字节。

主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。从性能和存储空间方面考量，自增主键往往是更合理的选择。

#### 什么场景适合用业务字段直接做主键
- 只有一个索引
- 该索引必须是唯一索引

考虑到`尽量使用主键查询`原则，可以直接将这个索引设置为主键，避免每次查询需要搜索两棵树。

### 覆盖索引
回到主键索引树搜索的过程，我们称为回表。

语句1：`select * from T where k between 3 and 5`
这个查询过程读了 `k` 索引树的 `3` 条记录，回表了 `2` 次。

语句2：`select ID from T where k between 3 and 5`
这时只需要查 `ID` 的值，而 `ID` 的值已经在 `k` 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，索引 k 已经“覆盖了”我们的查询需求，我们称为覆盖索引。

由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。

### 最左前缀原则
`B+` 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。此处要了解 `B+` 的逻辑才能理解这句话。

如果要查的是所有名字第一个字是 `张` 的人， `SQL` 语句的条件是 `where name like ‘张 %’ `。这时，能够用上这个索引。

可以看到，不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 `N` 个字段，也可以是字符串索引的最左 `M` 个字符。

#### 在建立联合索引的时候，如何安排索引内的字段顺序

索引的复用能力。因为可以支持最左前缀，所以当已经有了 `(a,b)` 这个联合索引后，一般就不需要单独在 `a` 上建立索引了。因此，第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的。

如果两个字段都需要索引，考虑的原则就是空间了。比如 `a、b` 两个字段哪个占得字节多建立联合索引时就在前，另一个就单独再创建一个索引。

### 索引下推

语句：`select * from tuser where name like '张%' and age=10 and ismale=1;`

联合索引：`（name, age）`

在 `MySQL 5.6` 之前，查询 `like` 后只能从 `张` 相关的行后开始一个个回表。到主键索引上找出数据行，再对比后面条件的字段值。

而 `MySQL 5.6` 引入的索引下推优化（`index condition pushdown`)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

![无索引下推执行流程](https://raw.githubusercontent.com/wubuwei/backend_image/master/%E6%97%A0%E7%B4%A2%E5%BC%95%E4%B8%8B%E6%8E%A8.png)

![索引下推执行流程](https://raw.githubusercontent.com/wubuwei/backend_image/master/%E7%B4%A2%E5%BC%95%E4%B8%8B%E6%8E%A8.png)

## 5. MySQL 的锁

数据库锁设计的初衷是处理并发问题。作为多用户共享的资源，当出现并发访问的时候，数据库需要合理地控制资源的访问规则。而锁就是用来实现这些访问规则的重要数据结构。

根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类。

### 全局锁

全局锁就是对整个数据库实例加锁。

`MySQL` 提供了一个加全局读锁的方法，命令是 `Flush tables with read lock (FTWRL)`。

全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都 `select` 出来存成文本。

官方自带的逻辑备份工具是 `mysqldump`。当 `mysqldump` 使用参数 `–single-transaction` 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 `MVCC` 的支持，这个过程中数据是可以正常更新的。

`single-transaction` 方法只适用于所有的表使用事务引擎的库。

#### 既然要全库只读，为什么不使用 set global readonly=true 的方式呢？

- 一是，在有些系统中，`readonly` 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 `global` 变量的方式影响面更大，不建议使用。
- 二是，在异常处理机制上有差异。如果执行 `FTWRL` 命令之后由于客户端发生异常断开，那么 `MySQL` 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 `readonly` 之后，如果客户端发生异常，则数据库就会一直保持 `readonly` 状态，这样会导致整个库长时间处于不可写状态，风险较高。

业务的更新不只是增删改数据（`DML`)，还有可能是加字段等修改表结构的操作（`DDL`）。不论是哪种方法，一个库被全局锁上以后，你要对里面任何一个表做加字段操作，都是会被锁住的。


### 表级锁

`MySQL` 里面表级别的锁有两种：一种是表锁，一种是元数据锁（`meta data lock，MDL`)。

#### 表锁
表锁的语法是 `lock tables … read/write`。与 `FTWRL` 类似，可以用 `unlock tables` 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，`lock tables` 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

举个例子, 如果在某个线程 `A` 中执行 `lock tables t1 read, t2 write`; 这个语句，则其他线程写 `t1`、读写 `t2` 的语句都会被阻塞。同时，线程 `A` 在执行 `unlock tables` 之前，也只能执行读 `t1`、读写 `t2` 的操作。连写 `t1` 都不允许，自然也不能访问其他表。

#### MDL
`MDL` 不需要显式使用，在访问一个表的时候会被自动加上。`MDL` 的作用是，保证读写的正确性。

当对一个表做增删改查操作的时候，加 `MDL` 读锁；当要对表做结构变更操作的时候，加 `MDL` 写锁。
- 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。
- 读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。

`MDL` 会直到事务提交才释放，在做表结构变更的时候，一定要小心不要导致 `锁住线上查询和更新`。

`MDL` 作用是防止 `DDL` 和 `DML` 并发的冲突


### 行锁

行锁就是针对数据表中行记录的锁。比如事务 `A` 更新了一行，而这时候事务 `B` 也要更新同一行，则必须等事务 `A` 的操作完成后才能进行更新。

`MySQL` 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 `MyISAM` 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。`InnoDB` 是支持行锁的，这也是 `MyISAM` 被 `InnoDB` 替代的重要原因之一。

#### 两阶段锁
在 `InnoDB` 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。

如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。

#### 死锁和死锁检测
当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。

出现死锁以后，有两种策略：
- 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 `innodb_lock_wait_timeout` 来设置。
- 另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 `innodb_deadlock_detect` 设置为 `on`，表示开启这个逻辑。

每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 `O(n)` 的操作。假设有 `1000` 个并发线程要同时更新同一行，那么死锁检测操作就是 `100` 万这个量级的。

锁检测要耗费大量的 CPU 资源，怎么解决由这种热点行更新导致的性能问题呢？
- 关掉死锁检测
 - 如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。
 - 关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。

- 控制并发度
 - 比如同一行同时最多只有 `10` 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题;
 - 可以考虑放在多条记录上，比如 `10` 个记录，随机选其中一条记录来加。这样每次冲突概率变成原来的 `1/10`，可以减少锁等待个数，也就减少了死锁检测的 `CPU` 消耗。
